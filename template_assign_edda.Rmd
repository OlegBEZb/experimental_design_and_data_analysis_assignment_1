---
title: "Assignment 1"
author: "Oleg Litvinov, Oguzhan Yetkin, group 4"
date: "28 February 2022"
output:
  pdf_document: default
  html_document:
    df_print: paged
highlight: tango
fontsize: 11pt
editor_options: 
  chunk_output_type: inline
  markdown: 
    wrap: 72
---

## Exercise 1. Waiting time.

A researcher measured (in minutes) how long patients have to wait in the
waiting room of a doctor's office: 15.4, 17.9, 19.0, 0.5, 15.9, 2.7,
6.2, 2.5, 4.7, 6.9, 10.8, 24.3, 5.6, 23.0, 10.7. Denote the mean waiting
time by $\mu$.

```{r}
x <- as.numeric(list(15.4, 17.9, 19.0, 0.5, 15.9, 2.7, 6.2, 2.5, 
                     4.7, 6.9, 10.8, 24.3, 5.6, 23.0, 10.7))
```

### a) Check normality of the data. Assuming normality (irrespective of your conclusion about normality of the data), construct a 97%-CI for $\mu$. Evaluate the sample size needed to provide that the length of the 97%-CI is at most 2. Compute a bootstrap 97%-CI for $\mu$ and compare it to the above CI.

Let's check the normality using Shapiro-Wilk test. $H_0$ is that sample
$x$ came from normally distributed population.

```{r, fig.width=4, fig.height=8}
par(mfrow=c(3, 1))
shapiro.test(x)
hist(x)
qqnorm(x)
```

\
From the output, the p-value \> 0.05 implying that the distribution of
the data are not significantly different from normal distribution, i.e.
the null hypothesis can not be rejected. In other words, we can assume
the normality. From the other side, the histogram and the qqplot don't
look "very" normal.

Estimated mean value:

```{r}
mu = mean(x)
mu
```

Next, we are going to construct a 97%-CI for $\mu$. A confidence interval for an unknown parameter $\mu$ is a random interval around the point estimate, containing $\mu$ with, e.g., 95% (97% in our case) confidence. The standard
deviation $\sigma$ is unknown, therefore, we estimate it by $s$.

```{r}
s = sd(x)
s
```

The confidence interval in such a case is based on a t-distribution and
the upper t-quantile.

```{r}
alpha <- 1 - 0.97
n <- length(x)
ta <- qnorm(1-alpha/2) # not qt(1-alpha/2, df=n-1) because "Assuming normality"
ta
```

t-confidence interval of level 97% for $\mu$:

```{r}
CI_97 <- c(mu - ta*s/sqrt(n), mu + ta*s/sqrt(n))
CI_97
```

Next, we evaluate the sample size needed to provide that the length of
the 97%-CI is at most 2. For this, we have to solve
$t_{\alpha / 2} \frac{s}{\sqrt{n}} \leq E$ for $n$.

```{r}
E <- 1 # a half of an interval
n_min <- (ta*s/E)^2
n_min
```

To provide the length of the 97%-CI less than 2, we have to collect the
sample of at least `r ceiling(n_min)` objects.

Let's compute a bootstrap 97%-CI for $\mu$ using 1000 samples.

```{r}
B = 1000
Tstar = numeric(B)

for(i in 1:B) {
  Xstar = sample(x, replace=TRUE)
  Tstar[i] = mean(Xstar)
}

TstarLower = quantile(Tstar, alpha/2)
TstarUpper = quantile(Tstar, 1-alpha/2)

bootstrap_CI_97 <- c(2*mu - TstarUpper, 2*mu - TstarLower)
bootstrap_CI_97
```

The confidence intervals look very close to each other. The one,
calculated with a bootstrapping, is stochastic and therefore differs
from launch to launch.

The bootstrap CI is close to the CI based on asymptotic normality. Let CI1 be the bootstrap 97%-CI and CI2 be the 97%-CI based on asymptotic normality.The size of CI2 is smaller than the size of CI1 

### b) The doctor claims that the mean waiting time is less than 15 minutes. Under an assumption, verify this claim by a relevant t-test, explain the meaning of the CI in the R-output for this test. Propose and perform a suitable sign tests for this problem. Can we use yet another test based on ranks?

One-sided t-test with $H_0$: mean waiting time $\geq$ 15; $H_1$: mean
waiting time $<$ 15:

```{r}
t.test(x, mu=15, alt='l')
```

$H_0$ is rejected. The doctor's claim (alternative hypothesis) is
accepted. The confidence interval is also one-sided (left-sided). The
given value of 15 is outside CI and this also tells about rejecting
$H_0$.

A sign test for median of a single sample may be applied if we state the
claim as "the median waiting time is less than 15 minutes":

```{r}
# for binom test if you are taking sum(x<15) the alternative should be "g"
res = binom.test(sum(x<15), length(x), p = 0.5, alternative = "greater", conf.level = 0.95)
res
```

The calculated p-value is `r round(res$p.value, 3)`. Since this is not less than 0.05, we
fail to reject the null hypothesis. We do not have sufficient evidence
to say that median waiting time is greater than 15 minutes.

In the same manner one-sample Wilcoxon signed rank test may be applied. The one-sample Wilcoxon signed rank test is a non-parametric alternative to one-sample t-test when the data cannot be assumed to be normally distributed (but have to be symmetric). Itâ€™s used to determine whether the median of the sample is equal to a known standard value (i.e. theoretical value). $H_{0}: m \leq m_{0}$, $H_{a}: m>m_{0}$ (greater).

```{r}
wilcox.test(x, mu=15, alternative="greater")
```
The same conclusion from the Wilcoxon sign test. Failed to reject that $m \leq m_{0}$.

### c) Propose a way to compute the powers of the t-test and sign test from b) at $\mu$ = 14 and $\mu$ = 13, comment.

The powers may be computed during a simulation as a probability of
rejecting $H_0$ when $H_1$ is true. For this, we have to generate
samples from $H_1$. For both tests we can generate from normal
distribution with the mean of 15, 14, 13.

```{r}
B <- 1000

for(m in 13:15){
  ttest <- numeric(B)
  sign <- numeric(B)
  for(i in 1L:B){
    # sd=1 not s
    h1_sample = rnorm(n, mean=m, sd=1)
    
    ttest[i] <- t.test(h1_sample, mu=mu, alt='l')[[3]]
    sign[i] <- binom.test(sum(h1_sample<mu), length(h1_sample), p = 0.5, 
                          alternative = "greater", conf.level = 0.95)[[3]]
  }
  print(paste0("H1 mu=", m))
  print(paste0("t-test power ", sum(ttest < 0.05)/B))
  print(paste0("sign test power ", sum(sign < 0.05)/B))
}
```

conclusion should have focused on the performance of the test as we move further from
H0, and that t-test is more powerful under normality assumptions.

If we move further away from H0, the both tests perform better in terms of power.

### d) Let *p* be the probability that a patient has to wait longer than 15.5 minutes. Using asymptotic normality, the researcher computed the right end $\hat{p}_{r}$= 0.53 of the confidence interval $\left[\hat{p}_{l}, \hat{p}_{r}\right]$ for *p*. Recover the whole confidence interval and its confidence level.

Let's estimate a proportion of patients to wait longer than 15.5
minutes. $p\_hat$ is a point estimate for $p$.

```{r}
p_hat = mean(x > 15.5)
p_hat
```

(1-$\alpha$)-confidence interval for $p$ is
$\hat{p} \pm Z_{\alpha / 2} \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$

```{r}
p_hat_r <- 0.53
margin_error = p_hat_r - p_hat
p_hat_l <- p_hat - margin_error
p_hat_l
```

Let's calculate Z alpha/2 quantile:

```{r}
se <- sqrt((p_hat * (1 - p_hat)) / n)
z_alpha_by_2 <- margin_error / se
z_alpha_by_2
```

```{r}
alpha = (1 - pnorm(z_alpha_by_2))*2
1-alpha
```

It was a 0.89-confidence level for $p$

### e) The researcher also reported that there were 3 men and 2 women among 5 patients who had to wait more than 15.5 minutes, 4 men and 6 women among the remaining 10 patients. The researcher claims that the waiting time is different for men and women. Verify this claim by an appropriate test.

Here we test whether the proportions of men and women in two groups
waiting more and less than 15.5 minutes are significantly different. We
apply the approximate proportion test:

```{r}
prop.test(c(2, 6), c(5, 10))
```

There is no significant evidence that the waiting time is different for
men and women.

## **Exercise 2.** Seeded clouds.

To improve rain fall in dry areas, an experiment was carried out with 52
clouds. Scientists investigated whether the addition of silver nitrate
leads to more rainfall. They chose 26 out of a sample of 52 clouds and
seeded it with silver nitrate. The file clouds.txt contains the
precipitation values (records the rainfall in feet per acre) of seeded
and unseeded clouds.

```{r}
clouds <- read.table("data/clouds.txt", header=TRUE)

par(mfrow=c(2, 3))
hist(clouds$seeded)
hist(clouds$unseeded)
hist(clouds$unseeded - clouds$seeded)
qqnorm(clouds$seeded)
qqnorm(clouds$unseeded)
qqnorm(clouds$unseeded - clouds$seeded)
```

```{r}
shapiro.test(clouds$unseeded - clouds$seeded)
```

From the histograms we can easily notice that data is distributed not
normally. The distributions look closer to exponential. The difference
also is not distributed normally according to Shapiro-Wilk test.

### a) Test whether silver nitrate has an effect by performing three tests: the two samples t-test (argue whether the data are paired or not), the Mann-Whitney test and the Kolmogorov-Smirnov test. Indicate whether these tests are actually applicable for our research question. Comment on your findings.

The data might be counted as paired if the data was collected in the
following way: two more or less similar clouds are found not far from
each other and only one of them is seeded. In the target experiment, the
half of clouds was selected without any requirements so we are not
assuming that the samples are paired.

```{r}
t.test(clouds$unseeded, clouds$seeded, paired=FALSE)
```

According to two not paired samples t-test, the $H_0$ states that the
means are equal is not rejected. **T-test actually may not be performed on
our data as the columns are even approximately not distributed normally
as well as their difference**.

Mann-Whitney test doesn't assume normality and, therefore may be
applied. The data is continuous and we can limit the alternative to a
shift in location.

```{r}
wilcox.test(clouds$unseeded, clouds$seeded)
median(clouds$unseeded); median(clouds$seeded)
```

According to Mann-Whitney test, $H_0$ of equal means is rejected. The
underlying distribution of precipitation for seeded clouds is shifted to
the right from that of unseeded ones.

Kolmogorov-Smirnov test also doesn't assume normality. $H_0$: equality
of continuous distributions.

```{r, warning=FALSE}
ks.test(clouds$unseeded, clouds$seeded)
mean(clouds$unseeded); mean(clouds$seeded)
```

Kolmogorov-Smirnov test also rejects $H_0$. The mean amount of
precipitation is larger for seeded clouds than for unseeded.

### b) Repeat the procedures from a) first on the square root of the values in *clouds.txt*, then on the square root of the square root of the values in *clouds.txt*. Comment on your findings.

```{r, fig.width=6,fig.height=3}
unseeded_sqrt <- sqrt(clouds$unseeded)
seeded_sqrt <- sqrt(clouds$seeded)

par(mfrow=c(1, 2))
hist(seeded_sqrt)
hist(unseeded_sqrt)
```

Not the data looks more normal. Let's check it for normality once again.

```{r}
shapiro.test(unseeded_sqrt)
shapiro.test(seeded_sqrt)
```

The p-value \< 0.05 for both columns. This implies that the
distributions of the data are significantly different from normal
distribution. This means that t-test may not be performed on our data
and applied just for interest.

```{r, warning=FALSE}
t.test(unseeded_sqrt, seeded_sqrt, paired=FALSE)
wilcox.test(unseeded_sqrt, seeded_sqrt)
ks.test(unseeded_sqrt, seeded_sqrt)
```

In this case t-test rejects the $H_0$, so means of squared values a
significantly different. Interestingly, Wilcoxon and Kolmogorov-Smirnov
tests remained completely the same as they are both based on ranks. The
ranks remain the same because square root function increases
monotonically.

```{r, fig.width=6,fig.height=3}
unseeded_sqrt_sqrt <- sqrt(unseeded_sqrt)
seeded_sqrt_sqrt <- sqrt(seeded_sqrt)

par(mfrow=c(1, 2))
hist(seeded_sqrt_sqrt)
hist(unseeded_sqrt_sqrt)
```

Not the data looks normal. Let's check it for normality once again.

```{r}
shapiro.test(unseeded_sqrt_sqrt)
shapiro.test(seeded_sqrt_sqrt)
```

From the output, the p-value \> 0.05 for both columns implying that the
distributions of the data are not significantly different from normal
distribution. Only now, for 4th roots of columns we can apply t-test.

```{r, warning=FALSE}
t.test(unseeded_sqrt_sqrt, seeded_sqrt_sqrt, paired=FALSE)
wilcox.test(unseeded_sqrt_sqrt, seeded_sqrt_sqrt)
ks.test(unseeded_sqrt_sqrt, seeded_sqrt_sqrt)
```

Wilcoxon and Kolmogorov-Smirnov tests didn't change for the same reason
as before. But now all three tests reject $H_0$ and we can conclude that
for 4th roots of measurements, the columns are distributed differently.

### c) Let X1,...,X26 be the sample for seeded clouds (column *seeded*). Assuming X1,...,X26$\sim$Exp($\lambda$) and using the central limit theorem, find an estimate $\hat{\lambda}$ of $\lambda$ and construct a 95%-CI for $\lambda$. By using a bootstrap test with the test statistic T=median(X1,...,X26), test the hypothesis $H_0$:X1,...,X26$\sim$Exp($\lambda_0$)Â with the parameter $\lambda_0$=$\hat{\lambda}$. Test this also by the Kolmogorov-Smirnov test.

Graded as "incorrect CI incorrect ks"

```{r, fig.width=3,fig.height=3}
seeded <- clouds$seeded

B <- 1000
Tstar <- numeric(B)
for(i in 1:B){
  Xstar <- sample(seeded, replace=TRUE)
  Tstar[i] <- mean(Xstar)
}

hist(Tstar)
```

```{r}
lambda_hat <- 1/mean(Tstar)

alpha <- 1 - 0.95
deltastar <- 1/Tstar - lambda_hat
d <- quantile(deltastar, c(alpha/2, 1-alpha/2))
CI95 = lambda_hat - c(d[2], d[1])
lambda_hat; CI95
```

Next, we check $H_0$: X1,...,X26$\sim$Exp($\lambda_0$) with the
parameter $\lambda_0$=$\hat{\lambda}$ using a bootstrap test.

```{r}
B <- 1000
t <- median(seeded)
tstar <- numeric(B)
n <- length(seeded)
for(i in 1:B){
  xstar <- rexp(n, lambda_hat)
  tstar[i] <- median(xstar)
}
pl <- sum(tstar<t)/B
pr <- sum(tstar>t)/B
p <- 2*min(pl, pr)
pl;pr;p
```

There is no evidence against $H_0$. Let's test the same hypothesis with
Kolmogorov-Smirnov test:

```{r}
ks.test(seeded, rexp(n, lambda_hat))
```

This test also doesn't reject the null hypothesis.

### d) Using an appropriate test, verify whether the median precipitation for seeded clouds is less than 300. Next, design and perform a test to check whether the fraction of the seeded clouds with the precipitation less than 30 is at most 25%.

To check whether the median precipitation for seeded clouds is less than
300 ($H_1$), we will use binomial test for a proportion. The test is
non--parametric, so we do not assume that the data is normally
distributed. As the theoretical probabilities are equal, the binomial
test becomes its special case - sign test.

```{r}
# group with elements < 300 is GREATER (larger) than the opposite (>=) ~in other words~ median is lees than 300
# this is our H1 (alternative)
binom.test(sum(seeded<300), length(seeded), p = 0.5, 
           alternative = "greater", conf.level = 0.95)
```

Since this is not less than 0.05, we fail to reject the null hypothesis.
We do not have sufficient evidence to say that median precipitation for
seeded clouds is less than 300.

Similarly, we check whether the fraction of the seeded clouds with the
precipitation less than 30 is at most 25%.

```{r}
# group of interest - less than 30. At most 25 -> the group has to me smaller
binom.test(sum(seeded<30), length(seeded), p = 0.25, alternative = "less", conf.level = 0.95)
```

Again, we do not have sufficient evidence to say that the fraction of
the seeded clouds with the precipitation less than 30 is at most 25%.

## Exercise 3. Concentrations of epinephrine.

The concentrations (in nanograms per millimeter) of plasma epinephrine
were measured for 10 dogs under *isofluorane*, *halothane*, and
*cyclopropane* anesthesia, represented as three columns in data frame
[dogs.txt](https://canvas.vu.nl/courses/60044/files/4714886?wrap=1 "dogs.txt").
We are interested in differences in the concentration for the different
drugs.

```{r}
dogs <- read.table("data/dogs.txt", header=TRUE)
head(dogs)
```

### a) Is it reasonable to assume that the three columns of dogs.txt were taken from normal populations?

```{r}
shapiro.test(dogs$isofluorane)
shapiro.test(dogs$cyclopropane)
shapiro.test(dogs$halothane)
```

Only the data for isofluorane shows non-normal distribution with a
p-value of 0.03434. However the concentrations of plasma epinephrine
under cyclopropane and halothane are normally distributed. We conclude
that this dogs data is not from a normal population.

### b) Investigate whether the columns isofluorane and halothane are correlated. Apply relevant tests to verify whether the distributions of these columns are different. Is a permutation test applicable?

As isofluorane column is not normally distributed, we use non-parametric
correlation test.

```{r, warning=FALSE}
cor.test(dogs$isofluorane, dogs$halothane, method="pearson")
cor.test(dogs$isofluorane, dogs$halothane, method="spearman")
```

The result shows small correlation according to Cohen rho = 0.218846.
Therefore we conclude that the correlation is small and not significant.

To check whether the distributions of these columns are different, we
apply a permutation test as normality is not assumed.

```{r}
mystat <- function(x, y) {mean(x-y)}

B <- 1000; tstar <- numeric(B)

for (i in 1:B){
  dogstar <- t(apply(cbind(dogs[,1], dogs[,2]), 1, sample))
  tstar[i] <- mystat(dogstar[,1], dogstar[,2])
}

hist(tstar)

myt <- mystat(dogs[,1], dogs[,2])
pl <- sum(tstar<myt)/B
pr <- sum(tstar>myt)/B
p <- 2*min(pl, pr)
pl;pr;p
```

A permutation test with mean statistic didn't reject the $H_0$ that
there is no difference between the distributions of isofluorane and
halothane columns.

```{r}
wilcox.test(dogs$isofluorane, dogs$halothane)
```
H_0 of equal medians is not rejected.
```{r}
ks.test(dogs[,1], dogs[,2])
```
H_0 of the same population for both samples is not rejected.

### c) Conduct a one-way ANOVA to determine whether the type of drug has an effect on the concentration of plasma epinephrine. Give the estimated concentrations for each of the three anesthesia drugs.

```{r}
dogframe <- data.frame(concentration=as.vector(as.matrix(dogs)),
                    variety=factor(rep(1:3, each=10))) # ordered as iso, halo, cyclo

options(contrasts = rep ("contr.treatment", 2)) # or contr.sum

aov <- lm(concentration~variety, data=dogframe)
anova(aov)
```

First of all the data has been conducted to one column of data set and
then a one way anova has been conducted. The result of this one way
anova is significant (p = 0,011), therefore there is an effect of the
drug type on the concentration of plasma epinephrine.

We also have to check normality of errors.

```{r, fig.width=8, fig.height=4}
shapiro.test(residuals(aov))
par(mfrow=c(1,2)); qqnorm(residuals(aov)); plot(fitted(aov), residuals(aov))
```

Residuals look normal and the fitted values show no pattern against
them.

```{r}
# Show the levels
levels(dogframe$variety)
```

```{r}
summary(aov)$coefficients
iso = summary(aov)$coefficients[1]
halo = summary(aov)$coefficients[2]
cyclo = summary(aov)$coefficients[3]
```

The estimated concentrations are `r iso`, `r iso+halo`, `r iso+cyclo` for isofluorane,
halothane, and cyclopropane respectively. For halothane t-test doesn't
reveal a significant difference from 0.

### d) Does the Kruskal-Wallis test arrive at the same conclusion about the effect of drug as the test in c)? Explain possible differences between conclusions of the Kruskal-Wallis and ANOVA tests.

```{r}
kruskal.test(concentration ~ variety, data = dogframe)[[3]]
```

$H_0$ is not rejected. The Kruskal-Wallis test did not arrive at the
same conclusion as the one way ANOVA. Compared to the ANOVA, the
Kruskal-Wallis test is a non-parametric counterpart of ANOVA which does
not rely on normality but on ranks thereby a bit less powerful results
than 1-way ANOVA.

## Exercise 4. Hemoglobin in trout.

Hemoglobin is measured (g/100 ml.) in the blood of brown trout after 35
days of treatment with four rates of sulfamerazine: the daily rates of
0, 5, 10 and 15 g of sulfamerazine per 100 pounds of fish, denoted as
rates 1, 2, 3 and 4, respectively. (Beware that the levels of the factor
rate are coded by numbers.) Two methods (denoted as A and B) of
administering the sulfamerazine were used. The data is collected in data
set
[hemoglobin.txt](https://canvas.vu.nl/courses/60044/files/4714874?wrap=1 "hemoglobin.txt").

### a) Present an R-code for the randomization process to distribute 80 fishes over all combinations of levels of factors rate and method.

```{r}
blood <- read.table("data/hemoglobin.txt", header=TRUE)
blood$rate = as.factor(blood$rate)
blood$method = as.factor(blood$method)

# set.seed(42)
# rows <- sample(nrow(blood))
# randomized <- blood[rows, ]
I = 4 # 4 levels of rate
J = 2 # 2 levels of method
N = 10 # 80 observations/fishes (4*2*N = 80)
rbind(rep(1:I,each=N*J),rep(1:J,N*I),sample(1:(N*I*J)))
```

### b) Perform the two-way ANOVA to test for effects of factors rate, method and their interaction on the response variable hemoglobin. Comment on your findings.

We want to test the following null hypotheses:
1. no interaction between the two factors A and B, 
2. no main effect of the first factor A,
3. no main effect of the second factor B.

```{r}
res.aov3 <- aov(hemoglobin ~ rate * method, data = blood)
summary(res.aov3)
```

<!-- The results of the Two Way Anova analysis show that Rate has a -->
<!-- significant effect F = 11.933, p = 0.000905, but method has no significant -->
<!-- effect F = 1.032, p= 0.312963. Furthermore, there is no interaction -->
<!-- effect between rate and method F = 0.531, p = 0.468373. The results show -->
<!-- that only rate is a significant factor in influencing the Hemoglobin -->
<!-- levels. The method that is used is not important because it does not -->
<!-- influence the result, accordingly, the method does neither decrease nor -->
<!-- increase the influence of the rate. -->

As interaction is not significant, we check the additive model.
```{r}
res.aov4 <- aov(hemoglobin ~ rate + method, data = blood)
summary(res.aov4)
```
Method is still not important.

### c) Which of the two factors has the greatest influence? Is this a good question? Consider the additive model. Which combination of rate and method yield the highest hemoglobin? Estimate the mean hemoglobin value for rate 3 by using method A. What rate leads to the highest mean hemoglobin?

```{r}
hemo_lm <- lm(hemoglobin ~ rate + method, data = blood)
anova(hemo_lm)
```

The factor â€˜rateâ€™ has the greatest influence on hemoglobin, since rate has a significant effect on hemoglobin and method does not have a significant effect on hemoglobin. However, since there is no interaction between rate and method, we have to remove the interaction term from the model and create an additive model (above) where there is no interaction. Still, only the variable 'rate' has a main effect on hemoglobin, and not the variable â€˜methodâ€™.

```{r}
summary(hemo_lm)
```
The combination of the second rate and the B method yields the highest hemoglobin.

```{r}
# Estimate the mean hemoglobin value for rate 3 by using method A
predict(hemo_lm, data.frame(method="A", rate="3"), type="response")
```

Rate 2 leads to the highest mean hemoglobin according to the coefs.

### d) Test the null hypothesis that the hemoglobin is the same for all rates by a one-way ANOVA test, ignoring the variable method. Is it right/wrong or useful/not useful to perform this test on this dataset?

```{r}
res.aov <- aov(hemoglobin ~ rate, data = blood)
summary(res.aov)
```

Yes, it is useful because we already have shown that "method" has no
influence at all. And because we have already shown that rate does
significantly influence hemoglobin it is useful to know whether there is
a difference in the number of rates on hemoglobin.

```{r, fig.width=8, fig.height=4}
shapiro.test(residuals(res.aov))
par(mfrow=c(1,2)); qqnorm(residuals(res.aov)); plot(fitted(res.aov), residuals(res.aov))
```
The residuals look good.

## Exercise 5. Sour cream.

The file cream.txt contains data on an experiment to produce sour cream.
Yogurt was placed in sweet cream, and yogurt bacteria were allowed to
develop. Bacteria produce lactic acid, and as a surrogate for the number
of yogurt bacteria, the acidity of the cream was measured. Interest was
in the effect of the type of yogurt (denoted as *starter*) on *acidity*.
The mixtures of yogurt and sweet cream were kept at constant temperature
in a yogurt maker, in which five different positions could be used. The
experiment was carried out with five batches of sweet cream, which were
meant to have the same composition. With each batch each of five types
of starter was used, with the yogurt placed in one of the five
positions. The combinations of levels of three factors form a
three-dimensional latin square. (You may need to install the R-package
*lme4*, which is not included in the standard distribution of R.)

```{r}
cream <- read.table("data/cream.txt", header=TRUE)

cream$starter <- factor(cream$starter)
cream$position <- factor(cream$position)
cream$batch <- factor(cream$batch)
```

### a) Analyze the data in a three-way experiment without interactions with acidity as response and starter, batch and position as factors

```{r}
aovcream <- lm(acidity ~ batch + position + starter, data=cream)
# Performing Anova Test
anova(aovcream)
```

```{r, fig.width=12, fig.height=4}
shapiro.test(residuals(aovcream))
par(mfrow=c(1,3))
hist(residuals(aovcream))
qqnorm(residuals(aovcream))
qqline(residuals(aovcream))
plot(fitted(aovcream), residuals(aovcream))
```
To perform a three-way ANOVA test, we need to check normality. This is done by creating a QQ-plot and histogram of the residuals of the data. Additionally, the Shapiro-Wilk test was performed. The line in the QQ-plot looks linear and the distribution of the histogram can come from a normal distribution. Besides, the Shapiro-Wilk test had a p-value larger than 0.05 which means that the data comes from normal distribution. Therefore, a three-way ANOVA can be performed.

The residuals also look normal and the fitted values show no pattern
against them.

```{r}
summary(aovcream)
```

A three-way Anova is used to analyze this data. The results of the
analysis show that batch has a significant effect p = 0.00163 and
starter has a significant effect p = 2.904e-05. However position does
not show a significant effect p = 0.411.

Starter 1 is the intercept, which has a p-value of less than 0.05. Therefore there is a significant effect of starter 1 on acidity. While starter 2 has a p-value of 0.754, and therefore has no significant effect on acidity.

### b) Recall that the main interest is in the effect of starter on the acidity; factors *positions* and *batches* represent the block variables. Remove insignificant block variable(s) if there are such, and perform an ANOVA for the resulting "fixed effects" model. Which starter(s) lead to significantly different acidity?

Insignificant block variables, are variables that have a p-value larger than 0.05. So this is the block variable position, which has a p-value of 0.411. Conclusively, the block variable Position needs to be removed from the model.

```{r}
model <- lm(acidity ~ starter + batch, data=cream)
#Performing Anova Test
anova(model)
```
```{r}
summary(model)
```

After deleting the block variable position, only starter 4 leads to a significant effect on acidity p = 2.01e-05.

```{r, fig.width=12, fig.height=4}
shapiro.test(residuals(model))
par(mfrow=c(1,3))
hist(residuals(model))
qqnorm(residuals(model))
qqline(residuals(model))
plot(fitted(model), residuals(model))
```
The line in the QQ-plot looks linear and the distribution of the histogram can come from a normal distribution. Besides, the Shapiro-Wilk test had a p-value larger than 0.05 which means that the data comes from normal distribution. The residuals also look normal and the fitted values show no pattern against them.

### c) For the model from b), can we also apply the Friedman test to test whether there is an effect of starter on acidity? Motivate your answer.

Friedman test doesn't rely on normality as it's based on ranks and works
only with N=1.

In the Friedman test the data does not need to come from a normal distribution, but it can also be used when the data comes from a normal distribution, like in this case. Instead of using the mean of the groups like in an ANOVA test the Friedman makes use of ranks. However, this change does not make any difference in the use of this test. Therefore, the Friedman test can also be used in this application to test whether there is an effect of starter on acidity. However, the Friedman test is not necessary when the ANOVA test has already been performed.

```{r}
attach(cream)
friedman.test(acidity, starter, batch, data=cream)
```

$H_0$ is rejected. There is an effect of starter on acidity taking into
account the blocking factor batch.

### d) Repeat b) by performing a mixed effects analysis, modeling the block variable(s) (if there are any) as a random effect by using the function *lmer*. Compare your results to the results found by using the fixed effects model in b).

```{r}
if (!require("lme4")) install.packages("lme4")
library(lme4)
```

```{r}
cream_lmer <- lmer(acidity ~ starter + (1|batch), REML=FALSE, data=cream)
summary(cream_lmer)
```

When using the fixed effects model the variables 1 and starter 4 had a significant effect on acidity. In the mixed effects model variables starter 1, starter 3, starter 4 had a significant effect on acidity. So, with the mixed effect model, more starters have a significant effect on acidity.
