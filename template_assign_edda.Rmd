---
title: "Assignment template"
author: "James Bond, group 007"
date: "1 February 2033"
output:
  pdf_document: default
  html_document:
    df_print: paged
highlight: tango
fontsize: 11pt
editor_options: 
  chunk_output_type: inline
  markdown: 
    wrap: 72
---

## Short introduction to R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax
for authoring HTML, PDF, and MS Word documents. R Markdown files permit
you to interweave R code with ordinary text to produce well-formatted
data analysis reports that are easy to modify. The R Markdown file
itself shows the readers exactly how you got the results in your report.
For more details on using R Markdown see
[\color{blue}{\underline{http://rmarkdown.rstudio.com}}](http://rmarkdown.rstudio.com).

When you click the **Knit** button, a document will be generated that
includes both content as well as the output of any embedded R code
chunks within the document. For inline R code, surround code with back
ticks and r. R replaces inline code with its results. For example, two
plus one is `r 2+1`; for the build-in R dataset `cars`, there were
`r nrow(cars)` cars studied. You can embed an R code chunk like this:

```{r}
summary(cars)
```

### Figures

You can also embed plots, for example:

```{r,echo=FALSE,fig.height=3.5}
plot(cars)
```

Note that the `echo = FALSE` parameter was added to the code chunk to
prevent printing of the R code that generated the plot. Use knitr
options to style the output of a chunk. Place options in brackets above
the chunk. Other options with the defaults are: the `eval=FALSE` option
just displays the R code (and does not run it); `warning=TRUE` whether
to display warnings; `tidy=TRUE` wraps long code so it does not run off
the page.

You can control the size and placement of figures. For example, you can
put two figures (or more) next to each other. Use `par(mfrow=c(n,m))` to
create `n` by `m` plots in one picture in R. You can adjust the
proportions of figures by using the `fig.width` and `fig.height` chunk
options. These are specified in inches, and will be automatically scaled
down to fit within the handout margin. Chunk option `fig.align` takes
values `left`, `right`, or `center` (to align figures in the output
document).

```{r,fig.margin = TRUE,fig.width=6,fig.height=3,fig.align="center"}
par(mfrow=c(1,2)); x1=rnorm(50); hist(x1); qqnorm(x1)
```

You can arrange for figures to span across the entire page by using the
`fig.fullwidth` chunk option.

```{r,fig.fullwidth=TRUE,fig.height=3}
plot(iris$Sepal.Length,iris$Petal.Length,xlab="Sepal.Length",ylab="Petal.Length")
```

More about chunk options can be found at
[\color{blue}{\underline{https://yihui.name/knitr/options/}}](https://yihui.name/knitr/options/).

### Equations

To produce mathematical symbols, you can also include
\LaTeX expessions/equations in your report: inline
$\frac{d}{dx}\left(\int_{0}^{x} f(u)\,du\right)=f(x)$ and in the display
mode: <!-- \[ -->
<!-- \frac{d}{dx}\left( \int_{0}^{x} f(u)\,du\right)=f(x). -->
<!-- \] --> To be able to use this functionality, \LaTeX has to be
installed.

### Footnotes

Here is the use of a footnote[^1].

[^1]:
    ## Exercise 1. Waiting time

    A researcher measured (in minutes) how long patients have to wait in
    the waiting room of a doctor's office: 15.4, 17.9, 19.0, 0.5, 15.9,
    2.7, 6.2, 2.5, 4.7, 6.9, 10.8, 24.3, 5.6, 23.0, 10.7. Denote the
    mean waiting time by /mu.

### Images

Want an image? This will do it. To depict an image (say, `my_image.jpg`
which should be in your current working directory), use this command

<!-- ![caption for my image](my_image.jpg) -->

### Tables

Want a table? This will create one (note that the separators *do not*
have to be aligned).

| Table Header | Second Header |
|--------------|---------------|
| Table Cell   | Cell 2        |
| Cell 3       | Cell 4        |

You can also make table by using knit's `kable` function:

```{r echo=FALSE, results='asis'}
library(knitr)
kable(mtcars[1:5,],caption="A knit kable.")
```

### Block quote

> This will create a block quote, if you want one.

### Verbatim

    This text is displayed verbatim/preformatted.

### Links

Links: <http://example.com>, [in-text link to
Google](http://google.com).

This is a \hyperlink{target1}{{\color{blue}{\underline{hyperlink}}}}.

\hypertarget{target1}{{\color{blue}{\underline{This}}}}

is where the hyperlink jumps to.

### Itimization, italicized and embolded text

-   Single asterisks italicize text *like this*.
-   Double asterisks embolden text **like this**.

One more way to italicize and embold: *italic* and **bold**.

## Exercise 1

Below is a template for reporting the exercises from the assignments.

**a)** Here are some consequitive R-commands.

```{r}
x=rep(c("A","B"),each=5); x
sample(x)
x=rnorm(100)
```

Now the same code chunk but with all the output collapsed into signle
block.

```{r, collapse=TRUE}
x=rep(c("A","B"),each=5); x
sample(x)
x=rnorm(100)
```

**b)** Below we perform a one sample t-test for the artificial data
(that we generate ourselves).

```{r}
mu=0.2
x=rnorm(100,mu,1) # creating artificial data
t.test(x,mean=0)   # t.test(x,alternative=c("two.sided"),conf.level=0.95,mu=10)
```

**c)** We often do not need to report the whole output of R-commands,
only certain values of the output. For example, below we perform a
two-sample t-test and report only the (appropriately rounded) values of
t-statistics and the p-pavue.

```{r}
mu=0;nu=0.5
x=rnorm(50,mu,1); y=rnorm(50,nu,1) # creating artificial data
ttest=t.test(x,y) 
```

The value of t-statistics in the above evaluation is
`r round(ttest[[1]],2)` and the p-value is `r round(ttest[[3]],4)`.

## Exercite 1. Waiting time.

A researcher measured (in minutes) how long patients have to wait in the
waiting room of a doctor's office: 15.4, 17.9, 19.0, 0.5, 15.9, 2.7,
6.2, 2.5, 4.7, 6.9, 10.8, 24.3, 5.6, 23.0, 10.7. Denote the mean waiting
time by $\mu$.

```{r}
x <- as.numeric(list(15.4, 17.9, 19.0, 0.5, 15.9, 2.7, 6.2, 2.5, 4.7, 6.9, 10.8, 24.3, 5.6, 23.0, 10.7))
```

**a)** Check normality of the data. Assuming normality (irrespective of
your conclusion about normality of the data), construct a 97%-CI for
$\mu$. Evaluate the sample size needed to provide that the length of the
97%-CI is at most 2. Compute a bootstrap 97%-CI for $\mu$ and compare it
to the above CI.

Let's check the normality using Shapiro-Wilk test. $H_0$ is that sample
$x$ came from normally distributed population.

```{r}
shapiro.test(x)
```

From the output, the p-value \> 0.05 implying that the distribution of
the data are not significantly different from normal distribution, i.e.
the null hypothesis can not be rejected. In other words, we can assume
the normality.

Estimated mean value:

```{r}
mu = mean(x)
mu
```

Next, we are going to construct a 97%-CI for $\mu$. The standard
deviation $\sigma$ is unknown, therefore, we estimate it by $s$.

```{r}
s = sd(x)
s
```

The confidence interval in such a case is based on a t-distribution and
the upper t-quantile.

```{r}
alpha <- 1 - 0.97
n <- length(x)
ta <- qt(1-alpha/2, df=n-1)
ta
```

t-confidence interval of level 97% for $\mu$:

```{r}
CI_97 <- c(mu - ta*s/sqrt(n), mu + ta*s/sqrt(n))
CI_97
```

Next, we evaluate the sample size needed to provide that the length of
the 97%-CI is at most 2. For this, we have to solve
$t_{\alpha / 2} \frac{s}{\sqrt{n}} \leq E$ for $n$.

```{r}
E <- 2 
n_min <- (ta*s/E)^2
n_min
```

To provide the length of the 97%-CI less than 2, we have to collect the
sample of at lest 88 objects.

Let's compute a bootstrap 97%-CI for $\mu$ using 1000 samples.

```{r}
B = 1000
Tstar = numeric(B)

for(i in 1:B) {
  Xstar = sample(x, replace=TRUE)
  Tstar[i] = mean(Xstar)
}

TstarLower = quantile(Tstar, alpha/2)
TstarUpper = quantile(Tstar, 1-alpha/2)

bootstrap_CI_97 <- c(2*mu - TstarUpper, 2*mu - TstarLower)
bootstrap_CI_97
```

The confidence intervals look very close to each other. The one,
calculated with a bootstrapping, is stochastic and therefore differs
from launch to launch.

**b)** The doctor claims that the mean waiting time is less than 15
minutes. Under an assumption, verify this claim by a relevant t-test,
explain the meaning of the CI in the R-output for this test. Propose and
perform a suitable sign tests for this problem. Can we use yet another
test based on ranks?

One-sided t-test with $H_0$: mean waiting time $\geq$ 15; $H_1$: mean
waiting time $<$ 15:

```{r}
t.test(x, mu=15, alt='l')
```

$H_0$ is rejected. The doctor's claim (alternative hypothesis) is
accepted. The confidence interval is also one-sided (left-sided). The
given value of 15 is outside CI and this also tells about rejecting
$H_0$.

A sign test for median of a single sample may be applied if we state the
claim as "the median waiting time is less than 15 minutes":

```{r}
binom.test(sum(x<15), length(x), p = 0.5, alternative = "less", conf.level = 0.95)
```

The calculated p-value is 0.85. Since this is not less than 0.05, we
fail to reject the null hypothesis. We do not have sufficient evidence
to say that median waiting time is less than 15 minutes.

In the same manner one-sample Wilcoxon signed rank test may be applied.

**c)** Propose a way to compute the powers of the t-test and sign test
from b) at $\mu$ = 14 and $\mu$ = 13, comment.

The powers may be computed during a simulation as a probability of
rejecting $H_0$ when $H_1$ is true. For this, we have to generate
samples from $H_1$. For both tests we can generate from normal
distribution with the mean of 15, 14, 13.

```{r}
B <- 1000

for(m in 13:15){
  ttest <- numeric(B)
  sign <- numeric(B)
  for(i in 1L:B){
    h1_sample = rnorm(n, mean=m, sd=s)
    
    ttest[i] <- t.test(h1_sample, mu=mu, alt='l')[[3]]
    sign[i] <- binom.test(sum(h1_sample<mu), length(h1_sample), p = 0.5, 
                          alternative = "less", conf.level = 0.95)[[3]]
  }
  print(paste0("H1 mu=", m))
  print(paste0("t-test power ", sum(ttest < 0.05)/B))
  print(paste0("sign test power ", sum(sign < 0.05)/B))
}
```

**d)** Let *p* be the probability that a patient has to wait longer than
15.5 minutes. Using asymptotic normality, the researcher computed the
right end $\hat{p}_{r}$= 0.53 of the confidence interval
$\left[\hat{p}_{l}, \hat{p}_{r}\right]$ for *p*. Recover the whole
confidence interval and its confidence level.

Let's estimate a proportion of patients to wait longer than 15.5
minutes. $p\_hat$ is a point estimate for $p$.

```{r}
p_hat = mean(x > 15.5)
p_hat
```

(1-$\alpha$)-confidence interval for $p$ is
$\hat{p} \pm Z_{\alpha / 2} \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$

```{r}
p_hat_r <- 0.53
margin_error = p_hat_r - p_hat
p_hat_l <- p_hat - margin_error
p_hat_l
```

Let's calculate Z alpha/2 quantile:

```{r}
se <- sqrt((p_hat * (1 - p_hat)) / n)
z_alpha_by_2 <- margin_error / se
z_alpha_by_2
```

```{r}
alpha = (1 - pnorm(z_alpha_by_2))*2
1-alpha
```

It was a 0.89-confidence interval for $p$

**e)** The researcher also reported that there were 3 men and 2 women
among 5 patients who had to wait more than 15.5 minutes, 4 men and 6
women among the remaining 10 patients. The researcher claims that the
waiting time is different for men and women. Verify this claim by an
appropriate test.

Here we test whether the proportions of men and women in two groups
waiting more and less than 15.5 minutes are significantly different. We
apply the approximate proportion test:

```{r}
prop.test(c(2, 6), c(5, 10))
```

There is no significant evidence that the waiting time is different for
men and women.

## **Exercise 2.** Seeded clouds

\
To improve rain fall in dry areas, an experiment was carried out with 52
clouds. Scientists investigated whether the addition of silver nitrate
leads to more rainfall. They chose 26 out of a sample of 52 clouds and
seeded it with silver nitrate. The file clouds.txt contains the
precipitation values (records the rainfall in feet per acre) of seeded
and unseeded clouds.

```{r}
clouds <- read.table("data/clouds.txt", header=TRUE)

par(mfrow=c(2, 3))
hist(clouds$seeded)
hist(clouds$unseeded)
hist(clouds$unseeded - clouds$seeded)
qqnorm(clouds$seeded)
qqnorm(clouds$unseeded)
qqnorm(clouds$unseeded - clouds$seeded)
```

```{r}
shapiro.test(clouds$unseeded - clouds$seeded)
```

From the histograms we can easily notice that data is distributed not
normally. The distributions look closer to exponential. The difference
also is not distributed normally according to Shapiro-Wilk test.

a)  Test whether silver nitrate has an effect by performing three tests:
    the two samples t-test (argue whether the data are paired or not),
    the Mann-Whitney test and the Kolmogorov-Smirnov test. Indicate
    whether these tests are actually applicable for our research
    question. Comment on your findings.

The data might be counted as paired if the data was collected in the
following way: two more or less similar clouds are found not far from
each other and only one of them is seeded. In the target experiment, the
half of clouds was selected without any requirements so we are not
assuming that the samples are paired.

```{r}
t.test(clouds$unseeded, clouds$seeded, paired=FALSE)
```

According to two not paired samples t-test, the $H_0$ states that the
means are equal is not rejected. T-test actually may not be performed on
our data as the columns are even approximately not distributed normally
as well as their difference.

Mann-Whitney test doesn't assume normality and, therefore may be
applied. The data is continuous and we can limit the alternative to a
shift in location.

```{r}
wilcox.test(clouds$unseeded, clouds$seeded)
median(clouds$unseeded); median(clouds$seeded)
```

According to Mann-Whitney test, $H_0$ of equal means is rejected. The
underlying distribution of precipitation for seeded clouds is shifted to
the right from that of unseeded ones.

Kolmogorov-Smirnov test also doesn't assume normality. $H_0$: equality
of continuous distributions.

```{r}
ks.test(clouds$unseeded, clouds$seeded)
mean(clouds$unseeded); mean(clouds$seeded)
```

Kolmogorov-Smirnov test also rejects $H_0$. The mean amount of
precipitation is larger for seeded clouds than for unseeded.

b)  Repeat the procedures from a) first on the square root of the values
    in *clouds.txt*, then on the square root of the square root of the
    values in *clouds.txt*. Comment on your findings.

```{r}
unseeded_sqrt <- sqrt(clouds$unseeded)
seeded_sqrt <- sqrt(clouds$seeded)

par(mfrow=c(1, 2))
hist(seeded_sqrt)
hist(unseeded_sqrt)
```

Not the data looks more normal. Let's check it for normality once again.

```{r}
shapiro.test(unseeded_sqrt)
shapiro.test(seeded_sqrt)
```

The p-value \< 0.05 for both columns. This implies that the
distributions of the data are significantly different from normal
distribution. This means that t-test may not be performed on our data
and applied just for interest.

```{r}
t.test(unseeded_sqrt, seeded_sqrt, paired=FALSE)
wilcox.test(unseeded_sqrt, seeded_sqrt)
ks.test(unseeded_sqrt, seeded_sqrt)
```

In this case t-test rejects the $H_0$, so means of squared values a
significantly different. Interestingly, Wilcoxon and Kolmogorov-Smirnov
tests remained completely the same as they are both based on ranks. The
ranks remain the same because square root function increases
monotonically.

```{r}
unseeded_sqrt_sqrt <- sqrt(unseeded_sqrt)
seeded_sqrt_sqrt <- sqrt(seeded_sqrt)

par(mfrow=c(1, 2))
hist(seeded_sqrt_sqrt)
hist(unseeded_sqrt_sqrt)
```

Not the data looks normal. Let's check it for normality once again.

```{r}
shapiro.test(unseeded_sqrt_sqrt)
shapiro.test(seeded_sqrt_sqrt)
```

From the output, the p-value \> 0.05 for both columns implying that the
distributions of the data are not significantly different from normal
distribution. Only now, for 4th roots of columns we can apply t-test.

```{r}
t.test(unseeded_sqrt_sqrt, seeded_sqrt_sqrt, paired=FALSE)
wilcox.test(unseeded_sqrt_sqrt, seeded_sqrt_sqrt)
ks.test(unseeded_sqrt_sqrt, seeded_sqrt_sqrt)
```

Wilcoxon and Kolmogorov-Smirnov tests didn't change for the same reason
as before. But now all three tests reject $H_0$ and we can conclude that
for 4th roots of measurements, the columns are distributed differently.

c)  Let X1,...,X26 be the sample for seeded clouds (column *seeded*).
    Assuming X1,...,X26$\sim$Exp($\lambda$) and using the central limit
    theorem, find an estimate $\hat{\lambda}$ of $\lambda$ and construct
    a 95%-CI for $\lambda$. By using a bootstrap test with the test
    statistic T=median(X1,...,X26), test the hypothesis
    $H_0$:X1,...,X26$\sim$Exp($\lambda_0$) with the parameter
    $\lambda_0$=$\hat{\lambda}$. Test this also by the
    Kolmogorov-Smirnov test.

    ```{r}
    seeded <- clouds$seeded

    B <- 1000
    Tstar <- numeric(B)
    for(i in 1:B){
      Xstar <- sample(seeded, replace=TRUE)
      Tstar[i] <- mean(Xstar)
    }
    lambda_hat <- 1/mean(Tstar)
    lambda_hat
    hist(Tstar)
    ```

    ```{r}
    alpha <- 1 - 0.95
    deltastar <- 1/Tstar - lambda_hat
    d <- quantile(deltastar, c(alpha/2, 1-alpha/2))
    CI95 = lambda_hat - c(d[2], d[1])
    lambda_hat; CI95
    ```

    Next, we check $H_0$: X1,...,X26$\sim$Exp($\lambda_0$) with the
    parameter $\lambda_0$=$\hat{\lambda}$ using a bootstrap test.

    ```{r}
    B <- 1000
    t <- median(seeded)
    tstar <- numeric(B)
    n <- length(seeded)
    for(i in 1:B){
      xstar <- rexp(n, lambda_hat)
      tstar[i] <- median(xstar)
    }
    pl <- sum(tstar<t)/B
    pr <- sum(tstar>t)/B
    p <- 2*min(pl, pr)
    pl;pr;p
    ```

    There is no evidence against $H_0$. Let's test the same hypothesis
    with Kolmogorov-Smirnov test:

    ```{r}
    ks.test(seeded, rexp(n, lambda_hat))
    ```

    This test also doesn't reject the null hypothesis.

d)  Using an appropriate test, verify whether the median precipitation
    for seeded clouds is less than 300. Next, design and perform a test
    to check whether the fraction of the seeded clouds with the
    precipitation less than 30 is at most 25%.

To check whether the median precipitation for seeded clouds is less than
300 ($H_1$), we will use binomial test for a proportion. The test is
non--parametric, so we do not assume that the data is normally
distributed. As the theoretical probabilities are equal, the binomial
test becomes its special case - sign test.

```{r}
binom.test(sum(seeded<300), length(seeded), p = 0.5, alternative = "less", conf.level = 0.95)
```

Since this is not less than 0.05, we fail to reject the null hypothesis.
We do not have sufficient evidence to say that median precipitation for
seeded clouds is less than 300.

Similarly, we check whether the fraction of the seeded clouds with the
precipitation less than 30 is at most 25%.

```{r}
binom.test(sum(seeded<30), length(seeded), p = 0.25, alternative = "less", conf.level = 0.95)
```

Again, we do not have sufficient evidence to say that the fraction of
the seeded clouds with the precipitation less than 30 is at most 25%.
